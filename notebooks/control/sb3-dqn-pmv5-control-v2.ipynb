{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06fbafa8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-30T12:38:04.680064Z",
     "iopub.status.busy": "2024-04-30T12:38:04.679715Z",
     "iopub.status.idle": "2024-04-30T12:39:09.084177Z",
     "shell.execute_reply": "2024-04-30T12:39:09.082994Z"
    },
    "papermill": {
     "duration": 64.411271,
     "end_time": "2024-04-30T12:39:09.086626",
     "exception": false,
     "start_time": "2024-04-30T12:38:04.675355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install stable-baselines3[extra]\n",
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c41ebd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T12:39:09.094064Z",
     "iopub.status.busy": "2024-04-30T12:39:09.093426Z",
     "iopub.status.idle": "2024-04-30T12:39:27.356811Z",
     "shell.execute_reply": "2024-04-30T12:39:27.355934Z"
    },
    "papermill": {
     "duration": 18.269664,
     "end_time": "2024-04-30T12:39:27.359363",
     "exception": false,
     "start_time": "2024-04-30T12:39:09.089699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 12:39:16.581158: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-30 12:39:16.581292: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-30 12:39:16.737097: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CallbackList\n",
    "from stable_baselines3.common.logger import TensorBoardOutputFormat, Video\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "from typing import Any, Dict\n",
    "\n",
    "import gymnasium as gym\n",
    "import torch as th\n",
    "import numpy as np\n",
    "\n",
    "CALLBACK_FREQ = 50000\n",
    "FRAMESKIP = 1\n",
    "NUM_TIMESTEPS = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e02c38d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T12:39:27.367484Z",
     "iopub.status.busy": "2024-04-30T12:39:27.366886Z",
     "iopub.status.idle": "2024-04-30T12:39:27.378541Z",
     "shell.execute_reply": "2024-04-30T12:39:27.377718Z"
    },
    "papermill": {
     "duration": 0.017849,
     "end_time": "2024-04-30T12:39:27.380668",
     "exception": false,
     "start_time": "2024-04-30T12:39:27.362819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VideoRecorderCallback(BaseCallback):\n",
    "    def __init__(self, eval_env: gym.Env, render_freq: int, n_eval_episodes: int = 1, deterministic: bool = True):\n",
    "        \"\"\"\n",
    "        Records a video of an agent's trajectory traversing ``eval_env`` and logs it to TensorBoard\n",
    "\n",
    "        :param eval_env: A gym environment from which the trajectory is recorded\n",
    "        :param render_freq: Render the agent's trajectory every eval_freq call of the callback.\n",
    "        :param n_eval_episodes: Number of episodes to render\n",
    "        :param deterministic: Whether to use deterministic or stochastic policy\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._eval_env = eval_env\n",
    "        self._render_freq = render_freq\n",
    "        self._n_eval_episodes = n_eval_episodes\n",
    "        self._deterministic = deterministic\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self._render_freq == 0:\n",
    "            screens = []\n",
    "\n",
    "            def grab_screens(_locals: Dict[str, Any], _globals: Dict[str, Any]) -> None:\n",
    "                \"\"\"\n",
    "                Renders the environment in its current state, recording the screen in the captured `screens` list\n",
    "\n",
    "                :param _locals: A dictionary containing all local variables of the callback's scope\n",
    "                :param _globals: A dictionary containing all global variables of the callback's scope\n",
    "                \"\"\"\n",
    "                screen = self._eval_env.render()\n",
    "                # PyTorch uses CxHxW vs HxWxC gym (and tensorflow) image convention\n",
    "                screens.append(screen.transpose(2, 0, 1))\n",
    "\n",
    "            evaluate_policy(\n",
    "                self.model,\n",
    "                self._eval_env,\n",
    "                callback=grab_screens,\n",
    "                n_eval_episodes=self._n_eval_episodes,\n",
    "                deterministic=self._deterministic,\n",
    "            )\n",
    "            # Convert screens to a numpy array before passing to pytorch\n",
    "            screens_array = np.array(screens)\n",
    "            self.logger.record(\n",
    "                \"trajectory/video\",\n",
    "                Video(th.ByteTensor([screens_array]), fps=20),\n",
    "                exclude=(\"stdout\", \"log\", \"json\", \"csv\"),\n",
    "            )\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8019e03a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T12:39:27.387639Z",
     "iopub.status.busy": "2024-04-30T12:39:27.387384Z",
     "iopub.status.idle": "2024-04-30T12:39:27.832574Z",
     "shell.execute_reply": "2024-04-30T12:39:27.831813Z"
    },
    "papermill": {
     "duration": 0.451244,
     "end_time": "2024-04-30T12:39:27.834959",
     "exception": false,
     "start_time": "2024-04-30T12:39:27.383715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "eval_env = Monitor(gym.make(\"ALE/Pacman-v5\", render_mode=\"rgb_array\", frameskip=FRAMESKIP))\n",
    "train_env = gym.make(\"ALE/Pacman-v5\", render_mode=\"rgb_array\", frameskip=FRAMESKIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb1543da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T12:39:27.842890Z",
     "iopub.status.busy": "2024-04-30T12:39:27.842299Z",
     "iopub.status.idle": "2024-04-30T12:39:27.847231Z",
     "shell.execute_reply": "2024-04-30T12:39:27.846408Z"
    },
    "papermill": {
     "duration": 0.010935,
     "end_time": "2024-04-30T12:39:27.849231",
     "exception": false,
     "start_time": "2024-04-30T12:39:27.838296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(eval_env, log_path=\"./\", eval_freq=CALLBACK_FREQ, n_eval_episodes=5, deterministic=True, render=False)\n",
    "video_callback = VideoRecorderCallback(eval_env, render_freq=CALLBACK_FREQ)\n",
    "callback_list = CallbackList([eval_callback, video_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01eb4a09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T12:39:27.856575Z",
     "iopub.status.busy": "2024-04-30T12:39:27.856040Z",
     "iopub.status.idle": "2024-04-30T12:39:29.596936Z",
     "shell.execute_reply": "2024-04-30T12:39:29.595898Z"
    },
    "papermill": {
     "duration": 1.747298,
     "end_time": "2024-04-30T12:39:29.599443",
     "exception": false,
     "start_time": "2024-04-30T12:39:27.852145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = DQN(\n",
    "    \"CnnPolicy\",\n",
    "    train_env,\n",
    "    verbose=1,\n",
    "    buffer_size=100000,\n",
    "    tensorboard_log=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffcaca6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T12:39:29.607300Z",
     "iopub.status.busy": "2024-04-30T12:39:29.607007Z",
     "iopub.status.idle": "2024-04-30T14:38:52.933376Z",
     "shell.execute_reply": "2024-04-30T14:38:52.932368Z"
    },
    "papermill": {
     "duration": 7163.357728,
     "end_time": "2024-04-30T14:38:52.960555",
     "exception": false,
     "start_time": "2024-04-30T12:39:29.602827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ././control/_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7ec4700e3df0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7ec46ffd58d0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.47e+03 |\n",
      "|    ep_rew_mean      | 7.25     |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1275     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 5874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.84e+03 |\n",
      "|    ep_rew_mean      | 7.62     |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1282     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 14758    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | 8.33     |\n",
      "|    exploration_rate | 0.772    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1289     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 23967    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.89e+03 |\n",
      "|    ep_rew_mean      | 8.31     |\n",
      "|    exploration_rate | 0.712    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1290     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 30303    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.88e+03 |\n",
      "|    ep_rew_mean      | 8.9      |\n",
      "|    exploration_rate | 0.642    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1291     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 37650    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | 8.71     |\n",
      "|    exploration_rate | 0.586    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1292     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 43601    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=1.00 +/- 0.00\n",
      "Episode length: 1678.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.68e+03 |\n",
      "|    mean_reward      | 1        |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "----------------------------------\n",
      "New best mean reward!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n",
      "/tmp/ipykernel_24/2676294641.py:43: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  Video(th.ByteTensor([screens_array]), fps=20),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.83e+03 |\n",
      "|    ep_rew_mean      | 8.89     |\n",
      "|    exploration_rate | 0.513    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 430      |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 51234    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.95e-05 |\n",
      "|    n_updates        | 308      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | 9.28     |\n",
      "|    exploration_rate | 0.45     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 57872    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.61e-05 |\n",
      "|    n_updates        | 1967     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.79e+03 |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.388    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 334      |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 64456    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.45e-06 |\n",
      "|    n_updates        | 3613     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | 10.5     |\n",
      "|    exploration_rate | 0.33     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 314      |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 70552    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.85e-05 |\n",
      "|    n_updates        | 5137     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | 11.8     |\n",
      "|    exploration_rate | 0.263    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 297      |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 77626    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.07e-05 |\n",
      "|    n_updates        | 6906     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.78e+03 |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.186    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 282      |\n",
      "|    time_elapsed     | 303      |\n",
      "|    total_timesteps  | 85663    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000255 |\n",
      "|    n_updates        | 8915     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.83e+03 |\n",
      "|    ep_rew_mean      | 16.7     |\n",
      "|    exploration_rate | 0.0975   |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 268      |\n",
      "|    time_elapsed     | 353      |\n",
      "|    total_timesteps  | 94996    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 11248    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=7.40 +/- 1.20\n",
      "Episode length: 1525.00 +/- 32.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.52e+03 |\n",
      "|    mean_reward      | 7.4      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 100000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000802 |\n",
      "|    n_updates        | 12499    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | 16.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 219      |\n",
      "|    time_elapsed     | 462      |\n",
      "|    total_timesteps  | 101689   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00224  |\n",
      "|    n_updates        | 12922    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | 16.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 212      |\n",
      "|    time_elapsed     | 509      |\n",
      "|    total_timesteps  | 108358   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000187 |\n",
      "|    n_updates        | 14589    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.79e+03 |\n",
      "|    ep_rew_mean      | 16.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 210      |\n",
      "|    time_elapsed     | 544      |\n",
      "|    total_timesteps  | 114831   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 16207    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 209      |\n",
      "|    time_elapsed     | 585      |\n",
      "|    total_timesteps  | 122295   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00354  |\n",
      "|    n_updates        | 18073    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | 18.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 207      |\n",
      "|    time_elapsed     | 625      |\n",
      "|    total_timesteps  | 129768   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000313 |\n",
      "|    n_updates        | 19941    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 206      |\n",
      "|    time_elapsed     | 667      |\n",
      "|    total_timesteps  | 137474   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.002    |\n",
      "|    n_updates        | 21868    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | 19.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 204      |\n",
      "|    time_elapsed     | 711      |\n",
      "|    total_timesteps  | 145649   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 23912    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=8.60 +/- 3.50\n",
      "Episode length: 1704.20 +/- 52.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.7e+03  |\n",
      "|    mean_reward      | 8.6      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 150000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 24999    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 187      |\n",
      "|    time_elapsed     | 817      |\n",
      "|    total_timesteps  | 152967   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 25741    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 185      |\n",
      "|    time_elapsed     | 865      |\n",
      "|    total_timesteps  | 160157   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00543  |\n",
      "|    n_updates        | 27539    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 185      |\n",
      "|    time_elapsed     | 899      |\n",
      "|    total_timesteps  | 166510   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 29127    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 185      |\n",
      "|    time_elapsed     | 934      |\n",
      "|    total_timesteps  | 172854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00318  |\n",
      "|    n_updates        | 30713    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | 18.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 185      |\n",
      "|    time_elapsed     | 974      |\n",
      "|    total_timesteps  | 180382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 32595    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 185      |\n",
      "|    time_elapsed     | 1009     |\n",
      "|    total_timesteps  | 186816   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 34203    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.79e+03 |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 185      |\n",
      "|    time_elapsed     | 1045     |\n",
      "|    total_timesteps  | 193383   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00233  |\n",
      "|    n_updates        | 35845    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=11.60 +/- 3.77\n",
      "Episode length: 22689.60 +/- 42647.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.27e+04 |\n",
      "|    mean_reward      | 11.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 200000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 37499    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | 20.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 152      |\n",
      "|    time_elapsed     | 1318     |\n",
      "|    total_timesteps  | 200479   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00729  |\n",
      "|    n_updates        | 37619    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | 21       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 152      |\n",
      "|    time_elapsed     | 1363     |\n",
      "|    total_timesteps  | 207576   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000512 |\n",
      "|    n_updates        | 39393    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 153      |\n",
      "|    time_elapsed     | 1397     |\n",
      "|    total_timesteps  | 213863   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00132  |\n",
      "|    n_updates        | 40965    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.79e+03 |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 1441     |\n",
      "|    total_timesteps  | 222152   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.142    |\n",
      "|    n_updates        | 43037    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 1474     |\n",
      "|    total_timesteps  | 228242   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 44560    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 155      |\n",
      "|    time_elapsed     | 1509     |\n",
      "|    total_timesteps  | 234746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00644  |\n",
      "|    n_updates        | 46186    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 156      |\n",
      "|    time_elapsed     | 1547     |\n",
      "|    total_timesteps  | 241652   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 47912    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.79e+03 |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 156      |\n",
      "|    time_elapsed     | 1587     |\n",
      "|    total_timesteps  | 249086   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 49771    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=10.40 +/- 1.50\n",
      "Episode length: 1549.00 +/- 142.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.55e+03 |\n",
      "|    mean_reward      | 10.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 250000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 49999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.79e+03 |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 152      |\n",
      "|    time_elapsed     | 1685     |\n",
      "|    total_timesteps  | 256753   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00793  |\n",
      "|    n_updates        | 51688    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 152      |\n",
      "|    time_elapsed     | 1725     |\n",
      "|    total_timesteps  | 263102   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 53275    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.75e+03 |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 153      |\n",
      "|    time_elapsed     | 1764     |\n",
      "|    total_timesteps  | 270354   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00153  |\n",
      "|    n_updates        | 55088    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 153      |\n",
      "|    time_elapsed     | 1807     |\n",
      "|    total_timesteps  | 278362   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 57090    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 1842     |\n",
      "|    total_timesteps  | 284795   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000796 |\n",
      "|    n_updates        | 58698    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 155      |\n",
      "|    time_elapsed     | 1877     |\n",
      "|    total_timesteps  | 291194   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00341  |\n",
      "|    n_updates        | 60298    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 155      |\n",
      "|    time_elapsed     | 1916     |\n",
      "|    total_timesteps  | 298443   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 62110    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=24.20 +/- 4.21\n",
      "Episode length: 1822.20 +/- 356.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.82e+03 |\n",
      "|    mean_reward      | 24.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 300000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000648 |\n",
      "|    n_updates        | 62499    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | 18.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 151      |\n",
      "|    time_elapsed     | 2023     |\n",
      "|    total_timesteps  | 305563   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 63890    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 151      |\n",
      "|    time_elapsed     | 2080     |\n",
      "|    total_timesteps  | 314637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00508  |\n",
      "|    n_updates        | 66159    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 151      |\n",
      "|    time_elapsed     | 2121     |\n",
      "|    total_timesteps  | 322160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 68039    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | 20.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 152      |\n",
      "|    time_elapsed     | 2164     |\n",
      "|    total_timesteps  | 330204   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 70050    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 153      |\n",
      "|    time_elapsed     | 2205     |\n",
      "|    total_timesteps  | 337569   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 71892    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.79e+03 |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 153      |\n",
      "|    time_elapsed     | 2246     |\n",
      "|    total_timesteps  | 345115   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000974 |\n",
      "|    n_updates        | 73778    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=18.00 +/- 4.73\n",
      "Episode length: 1660.80 +/- 192.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.66e+03 |\n",
      "|    mean_reward      | 18       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 350000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00252  |\n",
      "|    n_updates        | 74999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 149      |\n",
      "|    time_elapsed     | 2369     |\n",
      "|    total_timesteps  | 353820   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00224  |\n",
      "|    n_updates        | 75954    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | 23.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 149      |\n",
      "|    time_elapsed     | 2414     |\n",
      "|    total_timesteps  | 360416   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00291  |\n",
      "|    n_updates        | 77603    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | 24       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 149      |\n",
      "|    time_elapsed     | 2456     |\n",
      "|    total_timesteps  | 368095   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00308  |\n",
      "|    n_updates        | 79523    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | 24.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 150      |\n",
      "|    time_elapsed     | 2493     |\n",
      "|    total_timesteps  | 374848   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 81211    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.83e+03 |\n",
      "|    ep_rew_mean      | 23.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 151      |\n",
      "|    time_elapsed     | 2542     |\n",
      "|    total_timesteps  | 383961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00297  |\n",
      "|    n_updates        | 83490    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.86e+03 |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 151      |\n",
      "|    time_elapsed     | 2592     |\n",
      "|    total_timesteps  | 393114   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00562  |\n",
      "|    n_updates        | 85778    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=28.80 +/- 18.25\n",
      "Episode length: 1943.00 +/- 525.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.94e+03 |\n",
      "|    mean_reward      | 28.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 400000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 87499    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.89e+03 |\n",
      "|    ep_rew_mean      | 24.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 147      |\n",
      "|    time_elapsed     | 2728     |\n",
      "|    total_timesteps  | 402430   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 88107    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.9e+03  |\n",
      "|    ep_rew_mean      | 25.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 147      |\n",
      "|    time_elapsed     | 2793     |\n",
      "|    total_timesteps  | 412428   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00329  |\n",
      "|    n_updates        | 90606    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | 25.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 148      |\n",
      "|    time_elapsed     | 2836     |\n",
      "|    total_timesteps  | 420166   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 92541    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | 25.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 148      |\n",
      "|    time_elapsed     | 2872     |\n",
      "|    total_timesteps  | 426858   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 94214    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.93e+03 |\n",
      "|    ep_rew_mean      | 26.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 149      |\n",
      "|    time_elapsed     | 2913     |\n",
      "|    total_timesteps  | 434324   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00222  |\n",
      "|    n_updates        | 96080    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | 26.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 149      |\n",
      "|    time_elapsed     | 2952     |\n",
      "|    total_timesteps  | 441455   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00724  |\n",
      "|    n_updates        | 97863    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | 28.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 149      |\n",
      "|    time_elapsed     | 2993     |\n",
      "|    total_timesteps  | 448927   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00186  |\n",
      "|    n_updates        | 99731    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=19.40 +/- 2.42\n",
      "Episode length: 1513.80 +/- 89.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.51e+03 |\n",
      "|    mean_reward      | 19.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 450000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00296  |\n",
      "|    n_updates        | 99999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | 28.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 145      |\n",
      "|    time_elapsed     | 3131     |\n",
      "|    total_timesteps  | 454961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00297  |\n",
      "|    n_updates        | 101240   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | 28.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 3187     |\n",
      "|    total_timesteps  | 462122   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00662  |\n",
      "|    n_updates        | 103030   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.91e+03 |\n",
      "|    ep_rew_mean      | 29.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 145      |\n",
      "|    time_elapsed     | 3229     |\n",
      "|    total_timesteps  | 469797   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 104949   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.93e+03 |\n",
      "|    ep_rew_mean      | 29.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 145      |\n",
      "|    time_elapsed     | 3271     |\n",
      "|    total_timesteps  | 477552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 106887   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.93e+03 |\n",
      "|    ep_rew_mean      | 30.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 146      |\n",
      "|    time_elapsed     | 3309     |\n",
      "|    total_timesteps  | 484500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00535  |\n",
      "|    n_updates        | 108624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | 31.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 146      |\n",
      "|    time_elapsed     | 3360     |\n",
      "|    total_timesteps  | 493727   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00206  |\n",
      "|    n_updates        | 110931   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=26.20 +/- 3.54\n",
      "Episode length: 2228.80 +/- 338.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.23e+03 |\n",
      "|    mean_reward      | 26.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 500000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00829  |\n",
      "|    n_updates        | 112499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | 31.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 3495     |\n",
      "|    total_timesteps  | 502225   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 113056   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | 30       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 3553     |\n",
      "|    total_timesteps  | 510931   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00347  |\n",
      "|    n_updates        | 115232   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 30.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 3604     |\n",
      "|    total_timesteps  | 520348   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00205  |\n",
      "|    n_updates        | 117586   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | 32.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 3654     |\n",
      "|    total_timesteps  | 529246   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00352  |\n",
      "|    n_updates        | 119811   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | 32.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 145      |\n",
      "|    time_elapsed     | 3692     |\n",
      "|    total_timesteps  | 536305   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 121576   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 32.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 145      |\n",
      "|    time_elapsed     | 3731     |\n",
      "|    total_timesteps  | 543499   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00492  |\n",
      "|    n_updates        | 123374   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=27.20 +/- 3.71\n",
      "Episode length: 1745.60 +/- 148.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.75e+03 |\n",
      "|    mean_reward      | 27.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 550000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00577  |\n",
      "|    n_updates        | 124999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | 31.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 3841     |\n",
      "|    total_timesteps  | 550307   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00518  |\n",
      "|    n_updates        | 125076   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | 31.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 3887     |\n",
      "|    total_timesteps  | 557175   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 126793   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 32.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 3935     |\n",
      "|    total_timesteps  | 565970   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00222  |\n",
      "|    n_updates        | 128992   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 32.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 3974     |\n",
      "|    total_timesteps  | 573073   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 130768   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 32.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 4022     |\n",
      "|    total_timesteps  | 581884   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00665  |\n",
      "|    n_updates        | 132970   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | 33       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 145      |\n",
      "|    time_elapsed     | 4067     |\n",
      "|    total_timesteps  | 590172   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 135042   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | 32.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 145      |\n",
      "|    time_elapsed     | 4107     |\n",
      "|    total_timesteps  | 597423   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00308  |\n",
      "|    n_updates        | 136855   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=18.20 +/- 2.56\n",
      "Episode length: 1622.60 +/- 120.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.62e+03 |\n",
      "|    mean_reward      | 18.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 600000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 137499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.94e+03 |\n",
      "|    ep_rew_mean      | 33.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 4222     |\n",
      "|    total_timesteps  | 606473   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00357  |\n",
      "|    n_updates        | 139118   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | 33.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 4274     |\n",
      "|    total_timesteps  | 614697   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00672  |\n",
      "|    n_updates        | 141174   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | 33.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 4317     |\n",
      "|    total_timesteps  | 622535   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 143133   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | 37.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 4361     |\n",
      "|    total_timesteps  | 630579   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 145144   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | 38.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 4403     |\n",
      "|    total_timesteps  | 638331   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00297  |\n",
      "|    n_updates        | 147082   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 37.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 145      |\n",
      "|    time_elapsed     | 4450     |\n",
      "|    total_timesteps  | 647093   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00274  |\n",
      "|    n_updates        | 149273   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=35.20 +/- 6.68\n",
      "Episode length: 2326.40 +/- 332.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.33e+03 |\n",
      "|    mean_reward      | 35.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 650000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00963  |\n",
      "|    n_updates        | 149999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 37.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 4588     |\n",
      "|    total_timesteps  | 653301   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0058   |\n",
      "|    n_updates        | 150825   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | 37.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 4650     |\n",
      "|    total_timesteps  | 662412   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00371  |\n",
      "|    n_updates        | 153102   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | 37.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 4687     |\n",
      "|    total_timesteps  | 669312   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00815  |\n",
      "|    n_updates        | 154827   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | 37.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 4730     |\n",
      "|    total_timesteps  | 677217   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00447  |\n",
      "|    n_updates        | 156804   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | 37.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 4773     |\n",
      "|    total_timesteps  | 685123   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 158780   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | 38.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 4817     |\n",
      "|    total_timesteps  | 693326   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 160831   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=48.60 +/- 15.60\n",
      "Episode length: 2406.20 +/- 408.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.41e+03 |\n",
      "|    mean_reward      | 48.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 700000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00987  |\n",
      "|    n_updates        | 162499   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | 38.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 4946     |\n",
      "|    total_timesteps  | 700949   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00411  |\n",
      "|    n_updates        | 162737   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | 38.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 5002     |\n",
      "|    total_timesteps  | 709574   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 164893   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 39.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 5052     |\n",
      "|    total_timesteps  | 718845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 167211   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 37.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 5099     |\n",
      "|    total_timesteps  | 727423   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00138  |\n",
      "|    n_updates        | 169355   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | 37.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 5142     |\n",
      "|    total_timesteps  | 735447   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 171361   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | 38.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 5186     |\n",
      "|    total_timesteps  | 743465   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00425  |\n",
      "|    n_updates        | 173366   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=29.20 +/- 4.12\n",
      "Episode length: 1726.80 +/- 60.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.73e+03 |\n",
      "|    mean_reward      | 29.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 750000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0048   |\n",
      "|    n_updates        | 174999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | 38.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 5315     |\n",
      "|    total_timesteps  | 751125   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 175281   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | 39.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 5368     |\n",
      "|    total_timesteps  | 758925   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00307  |\n",
      "|    n_updates        | 177231   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | 39.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 5412     |\n",
      "|    total_timesteps  | 766993   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00625  |\n",
      "|    n_updates        | 179248   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | 39.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 5462     |\n",
      "|    total_timesteps  | 776185   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00256  |\n",
      "|    n_updates        | 181546   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | 39.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 5506     |\n",
      "|    total_timesteps  | 784365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00627  |\n",
      "|    n_updates        | 183591   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 40.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 5558     |\n",
      "|    total_timesteps  | 793837   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00661  |\n",
      "|    n_updates        | 185959   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=34.40 +/- 6.74\n",
      "Episode length: 1792.00 +/- 152.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.79e+03 |\n",
      "|    mean_reward      | 34.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 800000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 187499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | 40.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 5693     |\n",
      "|    total_timesteps  | 803797   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00132  |\n",
      "|    n_updates        | 188449   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 39.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 5741     |\n",
      "|    total_timesteps  | 810967   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 190241   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 40.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 5785     |\n",
      "|    total_timesteps  | 819120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00673  |\n",
      "|    n_updates        | 192279   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | 40.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 5829     |\n",
      "|    total_timesteps  | 827082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 194270   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 37.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 5869     |\n",
      "|    total_timesteps  | 834427   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0439   |\n",
      "|    n_updates        | 196106   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 37.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 5912     |\n",
      "|    total_timesteps  | 842234   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00359  |\n",
      "|    n_updates        | 198058   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | 36.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 5950     |\n",
      "|    total_timesteps  | 849294   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00395  |\n",
      "|    n_updates        | 199823   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=26.60 +/- 8.31\n",
      "Episode length: 1830.80 +/- 176.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.83e+03 |\n",
      "|    mean_reward      | 26.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 850000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0032   |\n",
      "|    n_updates        | 199999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | 37       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 6069     |\n",
      "|    total_timesteps  | 856432   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00271  |\n",
      "|    n_updates        | 201607   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | 37.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 6125     |\n",
      "|    total_timesteps  | 865009   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.023    |\n",
      "|    n_updates        | 203752   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 38       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 6172     |\n",
      "|    total_timesteps  | 873677   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 205919   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | 38.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 6219     |\n",
      "|    total_timesteps  | 882382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0026   |\n",
      "|    n_updates        | 208095   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | 38.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 6266     |\n",
      "|    total_timesteps  | 891129   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0389   |\n",
      "|    n_updates        | 210282   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | 37.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 6307     |\n",
      "|    total_timesteps  | 898477   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00308  |\n",
      "|    n_updates        | 212119   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=31.20 +/- 4.02\n",
      "Episode length: 2213.60 +/- 521.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.21e+03 |\n",
      "|    mean_reward      | 31.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 900000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0042   |\n",
      "|    n_updates        | 212499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | 37.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 140      |\n",
      "|    time_elapsed     | 6432     |\n",
      "|    total_timesteps  | 906509   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0501   |\n",
      "|    n_updates        | 214127   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | 37.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 6486     |\n",
      "|    total_timesteps  | 914797   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00539  |\n",
      "|    n_updates        | 216199   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | 37.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 6527     |\n",
      "|    total_timesteps  | 922262   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00372  |\n",
      "|    n_updates        | 218065   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 37.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 6579     |\n",
      "|    total_timesteps  | 931790   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00588  |\n",
      "|    n_updates        | 220447   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | 38.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 142      |\n",
      "|    time_elapsed     | 6639     |\n",
      "|    total_timesteps  | 942937   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0757   |\n",
      "|    n_updates        | 223234   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=37.80 +/- 4.07\n",
      "Episode length: 2271.20 +/- 322.14\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.27e+03 |\n",
      "|    mean_reward      | 37.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 950000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00368  |\n",
      "|    n_updates        | 224999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | 38.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 140      |\n",
      "|    time_elapsed     | 6773     |\n",
      "|    total_timesteps  | 950485   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00221  |\n",
      "|    n_updates        | 225121   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | 38.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 140      |\n",
      "|    time_elapsed     | 6831     |\n",
      "|    total_timesteps  | 959134   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00434  |\n",
      "|    n_updates        | 227283   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | 39.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 140      |\n",
      "|    time_elapsed     | 6885     |\n",
      "|    total_timesteps  | 969000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00426  |\n",
      "|    n_updates        | 229749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | 39.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 6932     |\n",
      "|    total_timesteps  | 977531   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 231882   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | 39.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 6976     |\n",
      "|    total_timesteps  | 985724   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0225   |\n",
      "|    n_updates        | 233930   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | 39.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 7016     |\n",
      "|    total_timesteps  | 992916   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 235728   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=49.20 +/- 7.76\n",
      "Episode length: 2379.60 +/- 478.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.38e+03 |\n",
      "|    mean_reward      | 49.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00413  |\n",
      "|    n_updates        | 237499   |\n",
      "----------------------------------\n",
      "New best mean reward!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7ec590945d20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=NUM_TIMESTEPS, callback=callback_list, tb_log_name=\"./control/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cb034d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T14:38:53.002460Z",
     "iopub.status.busy": "2024-04-30T14:38:53.001188Z",
     "iopub.status.idle": "2024-04-30T14:38:53.510389Z",
     "shell.execute_reply": "2024-04-30T14:38:53.509559Z"
    },
    "papermill": {
     "duration": 0.533247,
     "end_time": "2024-04-30T14:38:53.512690",
     "exception": false,
     "start_time": "2024-04-30T14:38:52.979443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"ALE-Pacman-v5-control-v2\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7255.484262,
   "end_time": "2024-04-30T14:38:57.137671",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-30T12:38:01.653409",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
